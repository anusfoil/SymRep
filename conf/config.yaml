

experiment:
  random_seed: 13
  fold_idx: 0  # determines the fold in sweep runs (8-fold, test_size=0.125) overridden by group runs
  exp_name: "${experiment.task}-${experiment.dataset}-${experiment.input_format}-${experiment.symrep}-fold${experiment.fold_idx}"
  grouped: 0  # the crossval runs are grouped
  group_name: "${experiment.task}-${experiment.dataset}-${experiment.input_format}-${experiment.symrep}-res${matrix.resolution}-chl${matrix.n_channels}"
  epoch: 300
  batch_size: 12
  lr: 1e-4
  lr_gamma: 0.99
  es_patience: 60     # early stopping patience
  es_threshold: 0.005  # early stopping threshold 
  
  restore_training: False
  device: [1]
  load_model: False
  artifact_dir: "'huanz/symrep/model-35lc0sy2:v9'"
  checkpoint_dir: "checkpoints/${experiment.exp_name}"
  checkpoint_file: "${experiment.checkpoint_dir}/epoch=49-step=1850.ckpt"

  dataset: ASAP  # ASAP or ATEPP
  task: composer_id  # composer_id, performer_id, difficulty_id
  input_format: perfmidi  # perfmidi, musicxml, kern
  symrep: matrix # matrix, sequence, graph
  emb_dim: 32 # frontend embedding from each segment

  data_save_dir: "/import/c4dm-datasets-ext/symrep_assets/${experiment.symrep}/${experiment.dataset}/${experiment.input_format}"
  load_data: True # wether load existing data
  feat_level: 0 # controls the amount of information for more standardized comparison. 0 for the basic, 1 for basic+extra 


segmentation:    # determine how the entire piece is segmented into local clips
  seg_type: fix_time  # fix_num, fix_size, fix_time
  seg_num: 4   # number of segments if seg_type==fix_nums
  seg_size: 300 # The V size of subgraph to sample if seg_type==fix_size.
  seg_time: 60 # in seconds if seg_type==fix_time. 
  seg_beat: 180 # in beats if seg_type==fix_time

# Representation
matrix:
  resolution: 600 # the width of matrix
  bins: 131 # 128 pitchs + 3 pedals
  n_channels: 2 # n channels of matrix. onset roll + frame roll (perfmidi: velocity, musicxml: voice) If=1 then only use the frame channel
  res_layers: [1, 1, 1, 1] # number layers in resnet structure. [2, 2, 2, 2] is for Resnet18
  save_dir: "${segmentation.seg_type}-(${segmentation.seg_num}|${segmentation.seg_size}|${segmentation.seg_time}|${segmentation.seg_beat})-${matrix.resolution}-${experiment.feat_level}" # furthur data parameters appended after the data_save_dir path

sequence:
  mid_encoding: REMI # MIDILike, REMI, CPWord
  pr_start: 21 
  pr_end: 109
  beat_res: 8  # 
  nb_velocities: 32
  vocab_size: [3, 35, 90, 3, 98, 34] # the final vocabulary size with each tokenization scheme. for CPWord it's a list. mid: [3, 35, 90, 3, 98, 34] xml: [3, 36, 192, 22, 14, 86]
  BPE: 0 # the scale of multiplying tokens into BPE. 0 is for disabled. 
  max_seq_len: 1600 # if BPE, then max_seq_len gets relatively smaller
  hid_dim: 512
  n_heads: 16
  save_dir: "${segmentation.seg_type}-(${segmentation.seg_num}|${segmentation.seg_size}|${segmentation.seg_time}|${segmentation.seg_beat})-${sequence.mid_encoding}-BPE${sequence.BPE}-${sequence.max_seq_len}-${experiment.feat_level}" # furthur data parameters appended after the data_save_dir path
  bpe_dir: "${experiment.data_save_dir}/${sequence.mid_encoding}-${experiment.feat_level}"  # directory for saving JSON token files for BPE learning

graph:
  homo: 0   # convert the graph back to homogeneous
  basic_edges: ['onset', 'consecutive', 'sustain', 'silence', 
      'consecutive_rev', 'sustain_rev', 'silence_rev'
      ]
  n_layers: 2
  hid_dim: 256
  bi_dir: True
  conv_type: SAGEConv # SAGEConv, GATConv
  mid_window: 0.03 # window for determine whether notes are same onset, consecutive and sustain

# DATASET 
dataset:
  ASAP:
    dataset_dir: /homes/hz009/Research/Datasets/asap-dataset/
    metadata_file: /homes/hz009/Research/Datasets/asap-dataset/metadata-v1.3.csv

  ATEPP: 
    dataset_dir: /homes/hz009/Research/Datasets/ATEPP-1.1/
    metadata_file: /homes/hz009/Research/Datasets/ATEPP-1.1/ATEPP-metadata-1.5.csv

  PD:
    dataset_dir: /homes/hz009/Research/Datasets/piano_difficulty/
    metadata_file: /homes/hz009/Research/Datasets/piano_difficulty/labels.csv

# HYDRA
defaults:  
  - _self_  
  # - override hydra/hydra_logging: disabled  
  # - override hydra/job_logging: disabled  
  
hydra:  
  output_subdir: null  
  run:  
    dir: .